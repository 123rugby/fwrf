{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use('gpu0') # some other variable would need to be set with the gpuarray backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import struct\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import ndimage as nd\n",
    "from scipy import misc\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as pim\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import src.numpy_utility as pnu\n",
    "import src.fwrf as prf\n",
    "from src.fwrf import FWRF_model, fpX\n",
    "from src.plots import display_candidate_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# folder in which resides the vim-1, dataset, the precalculated feature space and the image dataset.\n",
    "dataset_dir = \"/home/styvesg/Documents/PostDoc/Datasets/vim-1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timestamp = time.strftime('%b-%d-%Y_%H%M', time.localtime())\n",
    "\n",
    "root_dir   = os.getcwd() + '/'\n",
    "output_dir = root_dir+\"output/\"\n",
    "\n",
    "print \"Time Stamp: %s\" % timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a) Load the low-rez images presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputdata_lowrez = sio.loadmat(dataset_dir + \"Stimuli.mat\")\n",
    "print inputdata_lowrez.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "npx = 96\n",
    "npc = 3\n",
    "\n",
    "trn_size = len(inputdata_lowrez[\"stimTrn\"])\n",
    "val_size = len(inputdata_lowrez[\"stimVal\"])\n",
    "data_size = trn_size + val_size\n",
    "\n",
    "print \"trn: %d, val: %d\" % (trn_size, val_size)\n",
    "stim_data = np.ndarray(shape=(data_size, npx, npx, npc), dtype=fpX)\n",
    "\n",
    "for i,rawim in enumerate(inputdata_lowrez[\"stimTrn\"]):\n",
    "    rawmin, rawmax = np.min(rawim), np.max(rawim)\n",
    "    sim = (rawim - rawmin) * 255 / (rawmax - rawmin)               \n",
    "    im = pim.fromarray(sim, mode='F').resize((npx, npx), resample=pim.BILINEAR).convert('RGB')\n",
    "    stim_data[i,...] = np.asarray(im)\n",
    "\n",
    "for i,rawim in enumerate(inputdata_lowrez[\"stimVal\"]):\n",
    "    rawmin, rawmax = np.min(rawim), np.max(rawim)\n",
    "    sim = (rawim - rawmin) * 255 / (rawmax - rawmin)         \n",
    "    im = pim.fromarray(sim, mode='F').resize((npx, npx), resample=pim.BILINEAR).convert('RGB')\n",
    "    stim_data[trn_size+i,...] = np.asarray(im)\n",
    "        \n",
    "stim_data = np.transpose((stim_data - 128) / 128, (0,3,1,2))\n",
    "print \"Data shape = %s\" % (stim_data.shape,)\n",
    "\n",
    "trn_stim_data = stim_data[:trn_size]\n",
    "val_stim_data = stim_data[trn_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b) Load the voxel data for all images presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voxelset = h5py.File(dataset_dir + \"EstimatedResponses.mat\")\n",
    "print voxelset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject = 'S1'\n",
    "roi_names = ['other', 'V1', 'V2', 'V3', 'V3a', 'V3b', 'V4', 'LO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voxeldata = np.concatenate([voxelset['dataTrn%s'%subject], voxelset['dataVal%s'%subject]], axis=0).astype(dtype=fpX)\n",
    "voxelroi = voxelset['roi%s'%subject]\n",
    "voxelidx = voxelset['voxIdx%s'%subject]\n",
    "print voxeldata.shape\n",
    "\n",
    "# purge all voxel that have no variance in the validation set\n",
    "\n",
    "voxelNanMask = ~np.isnan(voxeldata).any(axis=0)\n",
    "nv = np.sum(voxelNanMask)\n",
    "print \"%d voxels contain valid values for all images\" % nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voxel_data = voxeldata[:, voxelNanMask].astype(dtype=fpX)\n",
    "voxelROI  = voxelroi[:, voxelNanMask]\n",
    "voxelIDX  = voxelidx[:, voxelNanMask]\n",
    "print voxel_data.shape\n",
    "\n",
    "trn_voxel_data = voxel_data[:trn_size]\n",
    "val_voxel_data = voxel_data[trn_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Restricted dataset to test the routines quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nv = 300\n",
    "start_v = (3566 // nv) * nv\n",
    "trn_voxel_data = trn_voxel_data[:, start_v:start_v+nv]\n",
    "val_voxel_data = val_voxel_data[:, start_v:start_v+nv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1c) Load precomputed model feature space for all images presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = 'deepnet'\n",
    "\n",
    "trn_feature_dict = h5py.File(dataset_dir + \"caffe_refnet_trn_response.h5py\", 'r')   # 'r' means that hdf5 file is open in read-only mode\n",
    "val_feature_dict = h5py.File(dataset_dir + \"caffe_refnet_val_response.h5py\", 'r')\n",
    "\n",
    "layerlist = trn_feature_dict.keys()\n",
    "print layerlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate and sort as list\n",
    "fmap_max = 1024\n",
    "order = layerlist[0:8] #+layerlist[7:8]\n",
    "fmaps = []\n",
    "fmaps_sizes = []\n",
    "fmaps_count = 0\n",
    "for l in order:\n",
    "    fmap = np.concatenate((np.array(trn_feature_dict[l], dtype=fpX), np.array(val_feature_dict[l], dtype=fpX)), axis=0)        \n",
    "    if fmap.ndim==2:\n",
    "        fmap = fmap.reshape(fmap.shape+(1,1))\n",
    "    if fmap.shape[1]>fmap_max:\n",
    "        #select the feature map with the most variance to the dataset\n",
    "        fmap_var = np.var(fmap[:trn_size], axis=(0,2,3))\n",
    "        most_var = fmap_var.argsort()[-fmap_max:]\n",
    "        fmap = fmap[:,most_var,:,:]\n",
    "    print \"layer: %s, shape=%s\" % (l, (fmap.shape))\n",
    "    fmaps += [fmap,]\n",
    "    fmaps_sizes  += [fmap.shape,]\n",
    "    fmaps_count += fmap.shape[1]\n",
    "    \n",
    "trn_feature_dict.close()\n",
    "val_feature_dict.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display an example of image and feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(trn_stim_data[5,0,:,:], cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(fmaps[0][5,2,:,:], interpolation='None')\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(fmaps[1][5,10,:,:], interpolation='None')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# aliases\n",
    "nf = fmaps_count\n",
    "fmaps_res_count = len(fmaps)\n",
    "\n",
    "# make sure we are using float32\n",
    "print fmaps[0].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) MODELS\n",
    "### There are 4 steps to the fwRF model\n",
    "1) Define the model object fwrf (class FWRF_model), where the input and batch sizes are initialized. This formulation is open ended: we need to provide feature maps of some sort but the input can be the feature maps themselves or any low level information and a theano expression that would generate these feature maps.\n",
    "\n",
    "2) Compute the model-space tensor (MST) by calling fwrf.precompute_mst_data(...) where one can choose a nonlinearity and normalize the final tensor.\n",
    "\n",
    "3) Run the model on the data by calling fwrf.shared_model_training(...). \"Shared model\" is the method, meaning that all voxels pick a model from the same grid.\n",
    "\n",
    "4) Run the resulting voxel models on the validation set to get an accuracy score. This can be done either with the MST of the validation with fwrf.validate_models(...) or by creating a new theano expression for the output of the fwRF model with the parameters learned in (3). To do this, use fwrf_symbolic_prediction(...). This returns a theano expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the inputs\n",
    "We can either connect the feature maps of the network directly or some precomputed values provided in a suitable list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature maps symbolic variables:\n",
    "_fmaps = []\n",
    "for r in range(fmaps_res_count):\n",
    "    _fmaps += [T.tensor4(),] # note this has to be done explicitely, we can't just replicate the tensor object\n",
    "_invar = _fmaps\n",
    "# vs. connecting another theano network directly:\n",
    "#_fmaps = [L.get_output(fm, deterministic=True) for fm in _aux]\n",
    "#_invar = [X,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lx = ly = 20.\n",
    "nx = ny = 10\n",
    "smin, smax = 0.7, 8.\n",
    "ns = 8\n",
    "\n",
    "# sharedModel specification is a list of 3 ranges and 3 callable functor. The reason for this is for a future implementation of dynamic mesh refinement.\n",
    "sharedModel_specs = [[(0., lx), (0., ly), (smin, smax)], [prf.linspace(nx), prf.linspace(ny), prf.logspace(ns)]]\n",
    "# initial values of the fwrf model parameters\n",
    "voxelParams = [np.full(shape=(nv, nf), fill_value=0.0, dtype=fpX), np.full(shape=(nv), fill_value=0.0, dtype=fpX)]\n",
    "\n",
    "rx = sharedModel_specs[1][0](*sharedModel_specs[0][0])\n",
    "ry = sharedModel_specs[1][1](*sharedModel_specs[0][1])\n",
    "rs = sharedModel_specs[1][2](*sharedModel_specs[0][2])\n",
    "print \"G = %d\\n\" % (nx*ny*ns)\n",
    "#print range:\n",
    "print \"range x\"\n",
    "print rx\n",
    "print \"range y\"\n",
    "print ry\n",
    "print \"range s\"\n",
    "print rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the indice of one of the receptive field size to visualize the rf weight masks at every resolution required by the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ith_rf_size = 0\n",
    "\n",
    "n = len(fmaps_sizes)\n",
    "plt.figure(figsize=(5*n,5))\n",
    "sigmas = sharedModel_specs[1][2](*sharedModel_specs[0][2])\n",
    "for i,r in enumerate(fmaps_sizes):\n",
    "    _,_,z = pnu.make_gaussian_mass(0., 0., sigmas[ith_rf_size], r[2], size=20.)\n",
    "    plt.subplot(1,n,i+1)\n",
    "    plt.imshow(z, interpolation='None')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "The model allocates the necessary buffers and pre-compile the theano expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fwrf = FWRF_model(_fmaps, fmaps_sizes, _invar, fmaps_sizes,\n",
    "    batches_p=(200, ny*nx), batches_o=(200, 300, ny*nx), batches_t=(200, 10*ny*nx),\\\n",
    "    view_angle=lx, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precompute and save the modelspace tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_act_func = lambda x: np.log(1+np.sqrt(np.abs(x)))\n",
    "log_act_func_2 = lambda x: np.log(np.power(1+np.square(x), 0.25))\n",
    "\n",
    "mst_data = fwrf.precompute_mst_data(fmaps, sharedModel_specs, verbose=True, dry_run=False, nonlinearity=log_act_func_2, \\\n",
    "                                        zscore=True, trn_size=trn_size, epsilon=1e-3)\n",
    "print mst_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.amin(mst_data), np.amax(mst_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the model space tensor into trn and val set.\n",
    "trn_mst_data = mst_data[:trn_size]\n",
    "val_mst_data = mst_data[trn_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_scores, best_scores, best_rf_params, best_candidates, best_w_params, best_avg, best_std = fwrf.shared_model_training(\\\n",
    "    trn_mst_data, trn_voxel_data, sharedModel_specs, voxelParams,\\\n",
    "    val_test_size=350, lr=1e-4, l2=0., num_epochs=40, output_val_scores=True, verbose=True, dry_run=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show a coarse distribution of position and sizes of the selected RFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "_,_,g_stack = pnu.make_gaussian_stack(best_rf_params[:,0], best_rf_params[:,1], best_rf_params[:,2], 64, size=20., dtype=fpX)\n",
    "plt.imshow(np.sum(g_stack, axis=0), interpolation='None')\n",
    "plt.subplot(1,2,2)\n",
    "_=plt.hist(best_rf_params[:,2], bins=50)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If output_val_scores was set to True, display the validation score for all candidate of one voxels and the time series of the best candidates for all voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vidx = 266\n",
    "print best_rf_params[vidx,:]\n",
    "fig1 = display_candidate_loss(val_scores[-1,vidx,:], nx, ny, ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for v in range(val_scores.shape[1]):\n",
    "    plt.plot(val_scores[:,v,best_candidates[v]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the best models and display the distribution of prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_pred, val_cc = fwrf.validate_models(val_mst_data, val_voxel_data, best_candidates, best_w_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"max cc = %f\" % np.max(val_cc)\n",
    "print \"sum(cc>0.2) = %d\" % np.sum(map(lambda x: x > 0.2, val_cc))\n",
    "plt.figure(figsize=(10,5))\n",
    "_=plt.hist(val_cc[:], bins=100, range=(-.5, 1.))\n",
    "plt.yscale('log')\n",
    "plt.ylim([10**-1, 10**3])\n",
    "plt.xlim([-.4, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(val_pred[:,vidx])\n",
    "plt.plot(val_voxel_data[:,vidx])\n",
    "\n",
    "print np.corrcoef(val_pred[:,vidx], val_voxel_data[:,vidx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex_file_name = \"fwrf_%s_%s_%s_data.pkl\" % (model_name, subject, timestamp)\n",
    "ex_file = open(output_dir + ex_file_name, 'wb')\n",
    "ex_values = {'dataset': 'vim-1',\n",
    "             'subject': subject,\n",
    "             'model_name': model_name,\n",
    "             'grid': [sharedModel_specs[1][0](*sharedModel_specs[0][0]), \n",
    "                      sharedModel_specs[1][1](*sharedModel_specs[0][1]),\n",
    "                      sharedModel_specs[1][2](*sharedModel_specs[0][2])],\n",
    "             'fmaps_res_count': fmaps_res_count,\n",
    "             'fmaps_count': fmaps_count,\n",
    "             'fmaps_sizes': fmaps_sizes,      \n",
    "             'scores': best_scores,\n",
    "             'rf_params': best_rf_params,\n",
    "             'w_params': best_w_params,\n",
    "             'normavg': best_avg,\n",
    "             'normstd': best_std, \n",
    "             'val_pred': val_pred,\n",
    "             'val_cc': val_cc}\n",
    "pickle.dump(ex_values, ex_file)\n",
    "ex_file.close()\n",
    "print ex_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Split accuracy by layer and roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find the start and end point of the feature map partitions\n",
    "fmaps_count = len(fmaps_sizes)\n",
    "partitions = [0,]\n",
    "for r in fmaps_sizes:\n",
    "    partitions += [partitions[-1]+r[1],]\n",
    "print partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "partition_val_pred = np.ndarray(shape=(fmaps_count,)+val_pred.shape, dtype=fpX)\n",
    "partition_val_cc   = np.ndarray(shape=(fmaps_count,)+val_cc.shape, dtype=fpX)\n",
    "\n",
    "for l in range(fmaps_count):\n",
    "    partition_params = [np.zeros(p.shape, dtype=fpX) for p in best_w_params]  \n",
    "    partition_params[0][:, partitions[l]:partitions[l+1]] = best_w_params[0][:, partitions[l]:partitions[l+1]]\n",
    "    partition_params[1][:] = best_w_params[1][:]\n",
    "\n",
    "    partition_val_pred[l,...], partition_val_cc[l,...] = fwrf.validate_models(val_mst_data, val_voxel_data, best_candidates, partition_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate covariances\n",
    "partition_r = np.ndarray(shape=(fmaps_count, nv))\n",
    "for v in range(nv):\n",
    "    full_c = np.cov(val_pred[:,v], val_voxel_data[:,v])\n",
    "    for l in range(fmaps_count):\n",
    "        part_c = np.cov(partition_val_pred[l,:,v], val_voxel_data[:,v])\n",
    "        partition_r[l,v] = part_c[0,1]/np.sqrt(full_c[0,0]*full_c[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "part_file = open(output_dir + \"fwrf_%s_%s_%s_part.pkl\" % (model_name, subject, timestamp), 'wb')\n",
    "part_values = {'dataset': 'vim-1',\n",
    "             'subject': subject,\n",
    "             'model_name': model_name,\n",
    "             'val_pred': partition_val_pred,\n",
    "             'val_cc': partition_val_cc,\n",
    "             'val_ri': partition_r}\n",
    "pickle.dump(part_values, part_file)\n",
    "part_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nROI = int(np.max(voxelROI))+1\n",
    "nL   = fmaps_count\n",
    "\n",
    "partition_R_avg = np.ndarray(shape=(fmaps_count, nROI), dtype=fpX)\n",
    "partition_R_std = np.ndarray(shape=(fmaps_count, nROI), dtype=fpX)\n",
    "for roi in range(nROI):\n",
    "    roi_mask = np.logical_and(voxelROI.flatten()==roi, val_cc>0.27)    \n",
    "    for l in range(fmaps_count):\n",
    "        partition_R_avg[l,roi] = np.mean(partition_r[l, roi_mask] /  val_cc[roi_mask])\n",
    "        partition_R_std[l,roi] = np.std(partition_r[l, roi_mask])\n",
    "#plt.imshow(partition_R_avg, interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cm \n",
    "color=iter(cm.magma(np.linspace(0,1,nL)))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "c=next(color)\n",
    "plist = []\n",
    "_ = plt.bar(np.arange(len(roi_names)), partition_R_avg[0,:], yerr=partition_R_std[0,:], color=c, align='center')\n",
    "plist += [_,]\n",
    "for l in range(1,nL):\n",
    "    c=next(color)\n",
    "    _= plt.bar(np.arange(len(roi_names)), partition_R_avg[l,:], bottom=np.sum(partition_R_avg[:l,:],axis=0), yerr=partition_R_std[l,:], color=c,\\\n",
    "        align='center', tick_label=roi_names)\n",
    "    plist += [_,]\n",
    "plt.legend(plist, ['layer %d' % l for l in range(1,len(plist)+1)])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('Layer contribution to total prediction accuracy\\n (averaged over voxels in roi)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
