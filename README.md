# fwrf
Example code and analysis for the paper: The feature-weighted receptive field: an interpretable encoding model for complex feature spaces

![diagram](/img/gabor_vs_refnet_fwrf_method.png)

## The \fwrf~model:
(A) A schematic illustration of a \fwrf~for a single voxel (grey box on brain, top right). The \fwrf~predicts the brain activity measured in the voxel, $r$, in response to any visual stimulus, $S$ (bottom left). The stimulus is transformed into one or more feature maps (three feature maps, $\Phi_k$, $\Phi_l$, and $\Phi_m$, are shown in blue with pink borders). The choice of feature maps is entirely up to the user, and reflects her hypotheses about the visual features that are relevant to brain regions of interest. The resolution of the feature maps ($\Delta$, indicated by pink grids) can vary, although each feature map spans the same degree of visual angle as the stimulus $S$. Each feature map is filtered by a 2D Gaussian feature pooling field, $g$, that is sampled from a grid of candidate \fpf s (grey box at top left; candidate \fpf~centers ($\mu_x,\mu_y$) are illustrated by the grid of black points, while candidate \fpf~radii ($\sigmag$) are illustrated by dashed circles). The \fpf~radius and location are the same for each feature map. The output of the \fpf~filtering operation (illustrated as black dots in the center of the dashed \fpf s on each feature map) for each feature map is then weighted by a feature weight (black curves labeled $w_k$, $w_l$, $w_m$). These weighted outputs are summed to produce a prediction of the activity $r$. In the text we describe an algorithm for selecting the optimal \fpf~and feature weights for each voxel. (B) Gabor wavelet feature maps are constructed by convolving the input images with complex Gabor wavelets followed by a compressive nonlinearity (see text for details). (C) Deepnet feature maps were extracted the layers (labeled $K_i$) of a deep convolutional network pre-trained to label images according to object category.
